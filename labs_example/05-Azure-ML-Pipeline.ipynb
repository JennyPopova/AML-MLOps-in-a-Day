{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Azure Machine Learning Pipeline\r\n",
        "\r\n",
        " In this notebook, we will be creating a Azure Machine Learning Pipeline for the complete stage of machine learning lifecycle:\r\n",
        " \r\n",
        " 1. Data Engineering\r\n",
        " 2. Model Training\r\n",
        " 3. Model Management\r\n",
        " 4. Model Deployment (to same environment)\r\n",
        " \r\n",
        "![Data Engineering](./images/00-Pipeline.jpg)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Engineering \r\n",
        "\r\n",
        "**Input** : Raw Data \r\n",
        "\r\n",
        "**Output** : Registered Data Set (ProductReview)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "if not os.path.exists('data_engineering'):\r\n",
        "    os.makedirs('data_engineering')"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923054962
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_engineering/data_engineering.py\r\n",
        "import os\r\n",
        "import json\r\n",
        "import gzip\r\n",
        "import pandas as pd\r\n",
        "from urllib.request import urlopen\r\n",
        "import requests\r\n",
        "\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.core import Dataset, Datastore, Workspace\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "\r\n",
        "# get run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# Download data from source\r\n",
        "url = \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Software_5.json.gz\"\r\n",
        "response = requests.get(url, stream=True)\r\n",
        "\r\n",
        "with open(\"Software_5.json.gz\", \"wb\") as handle:\r\n",
        "    for data in response.iter_content():\r\n",
        "        handle.write(data)\r\n",
        "\r\n",
        "### load the meta data\r\n",
        "data = []\r\n",
        "with gzip.open('Software_5.json.gz') as f:\r\n",
        "    for l in f:\r\n",
        "        data.append(json.loads(l.strip()))\r\n",
        "    \r\n",
        "# total length of list, this number equals total number of products\r\n",
        "print(len(data))\r\n",
        "\r\n",
        "# first row of the list\r\n",
        "print(data[0])\r\n",
        "df = pd.DataFrame.from_dict(data)\r\n",
        "\r\n",
        "### remove rows with unformatted title (i.e. some 'title' may still contain html style content)\r\n",
        "df3 = df.fillna('')\r\n",
        "df3.iloc[2]\r\n",
        "\r\n",
        "# register dataset\r\n",
        "workspace = run.experiment.workspace\r\n",
        "default_datastore = Datastore.get_default(workspace)\r\n",
        "\r\n",
        "ds_name = 'ProductReview'\r\n",
        "data_path = DataPath(datastore=default_datastore, path_on_datastore='product_review')\r\n",
        "\r\n",
        "ds = Dataset.Tabular.register_pandas_dataframe(df3, \r\n",
        "                                    default_datastore, \r\n",
        "                                    ds_name, \r\n",
        "                                    description=None, \r\n",
        "                                    tags=None, \r\n",
        "                                    show_progress=True)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting data_engineering/data_engineering.py\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1638856840545
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\r\n",
        "\r\n",
        "Use existing train_2.py from previous demo."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "if not os.path.exists('train'):\r\n",
        "    os.makedirs('train')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923068539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train/train_2.py\r\n",
        "# General libraries.\r\n",
        "import numpy as np\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import classification_report,plot_confusion_matrix, ConfusionMatrixDisplay\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from azureml.core.run import Run\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from azureml.core import Workspace, Dataset\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from joblib import dump\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# Get workspace from run context\r\n",
        "workspace = run.experiment.workspace\r\n",
        "\r\n",
        "# Load Data\r\n",
        "dataset = Dataset.get_by_name(workspace, name='ProductReview')\r\n",
        "data = dataset.to_pandas_dataframe()[['overall', 'reviewText']]\r\n",
        "\r\n",
        "# Prepare X & Y\r\n",
        "Y = data.pop('overall').to_numpy()\r\n",
        "X = data.pop('reviewText').to_numpy()\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(X,Y, test_size = 0.1, random_state=1)\r\n",
        "\r\n",
        "\r\n",
        "vec = CountVectorizer()\r\n",
        "fitted_train_data = vec.fit_transform(train_x)\r\n",
        "fitted_test_data = vec.transform(test_x)\r\n",
        "\r\n",
        "model = MultinomialNB()\r\n",
        "params = {'alpha': [1.0e-5, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]}\r\n",
        "\r\n",
        "clf = GridSearchCV(model, params, scoring = \"f1_macro\", verbose=0, cv = 5)\r\n",
        "clf_result = clf.fit(fitted_train_data, train_y)\r\n",
        "run.log(\"Best alpha\",clf_result.best_estimator_.alpha)\r\n",
        "pred = clf.predict(fitted_test_data)\r\n",
        "run.log(\"F1\", metrics.f1_score(test_y, pred, average='weighted'))\r\n",
        "\r\n",
        "plot_confusion_matrix(clf, fitted_test_data, test_y)  \r\n",
        "plt.savefig('confusion_matrix.png')\r\n",
        "run.log_image(name='Confusion-Matrix', path='./confusion_matrix.png')\r\n",
        "\r\n",
        "# Save trained model\r\n",
        "dump(vec, './vec.pkl')\r\n",
        "dump(clf, './mnb.pkl')\r\n",
        "run.upload_file(name='vec.pkl', path_or_stream='./vec.pkl')\r\n",
        "run.upload_file(name='mnb.pkl', path_or_stream='./mnb.pkl')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting train/train_2.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection\r\n",
        "\r\n",
        "In this step, we will use a predefined metrics **F1**. We will list all today's runs and select the highest F1 score model, which will be registered in Model Registry and prepare for deployment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "if not os.path.exists('model_selection'):\r\n",
        "    os.makedirs('model_selection')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923070059
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_selection/model_select.py\r\n",
        "import sklearn\r\n",
        "from datetime import datetime, date\r\n",
        "from azureml.core.run import Run\r\n",
        "# from azureml.core import Experiment\r\n",
        "# from azureml.core.model import Model\r\n",
        "\r\n",
        "# get run context\r\n",
        "run = Run.get_context()\r\n",
        "workspace = run.experiment.workspace\r\n",
        "\r\n",
        "# Get Experiment and runs for model select\r\n",
        "# In this step, we will use F1\r\n",
        "exp = run.experiment # Experiment.list(workspace, experiment_name='MLOps-Workshop')\r\n",
        "\r\n",
        "today = date.today()\r\n",
        "\r\n",
        "select_run = None\r\n",
        "F1 = 0\r\n",
        "for r in Run.list(exp, type=\"azureml.StepRun\", include_children=True):\r\n",
        "    run_starttime = datetime.strptime(r.get_details()['startTimeUtc'][:10], '%Y-%m-%d').date()\r\n",
        "    if run_starttime==today and 'F1' in r.get_metrics().keys() and F1<r.get_metrics()['F1']:\r\n",
        "        F1=r.get_metrics()['F1']\r\n",
        "        select_run = r\r\n",
        "    \r\n",
        "if select_run != None:\r\n",
        "    # Load Data\r\n",
        "    mnb_model = select_run.register_model(\"ProductReview-NaiveBayes\",\r\n",
        "                            model_path=\"./mnb.pkl\",\r\n",
        "                            )\r\n",
        "\r\n",
        "    vector    = select_run.register_model(\"ProductReview-CountVector\", \r\n",
        "                            model_path=\"./vec.pkl\",\r\n",
        "                            )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model_selection/model_select.py\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare for Model Package"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "if not os.path.exists('model_deploy'):\r\n",
        "    os.makedirs('model_deploy')"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923070833
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_deploy/score.py\r\n",
        "import json, os, joblib\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "def init(): \r\n",
        "  global vec, clf\r\n",
        "  print(Model.get_model_path('ProductReview-NaiveBayes'))\r\n",
        "  vec = joblib.load(Model.get_model_path('ProductReview-CountVector'))\r\n",
        "  clf = joblib.load(Model.get_model_path('ProductReview-NaiveBayes'))\r\n",
        "\r\n",
        "def run(data): \r\n",
        "  input_data = json.loads(data)['data'] \r\n",
        "  fitted_data = vec.transform(input_data)\r\n",
        "  pred = clf.predict(fitted_data)\r\n",
        "  return json.dumps(pred.tolist())\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model_deploy/score.py\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_deploy/deploy.py\r\n",
        "from azureml.core.model import InferenceConfig, Model\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.run import Run\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "# get run context\r\n",
        "run = Run.get_context()\r\n",
        "workspace = run.experiment.workspace\r\n",
        "\r\n",
        "service_name = 'product-review-service'\r\n",
        "env = Environment.get(workspace=workspace, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script='score.py', \r\n",
        "                            source_directory='.',\r\n",
        "                            environment=env)\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "nb_model = Model(workspace, 'ProductReview-NaiveBayes')\r\n",
        "vectorizor = Model(workspace, 'ProductReview-CountVector')\r\n",
        "\r\n",
        "service = Model.deploy(\r\n",
        "    workspace,\r\n",
        "    name = service_name,\r\n",
        "    models=[nb_model, vectorizor],\r\n",
        "    inference_config= inference_config,\r\n",
        "    deployment_config= deployment_config,\r\n",
        "    overwrite=True,\r\n",
        ")\r\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting model_deploy/deploy.py\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "from azureml.pipeline.core import Pipeline, PipelineData\r\n",
        "import azureml.core\r\n",
        "from azureml.core import Workspace, Environment, Experiment\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "import os\r\n",
        "\r\n",
        "workspace = Workspace.from_config()\r\n",
        "# Get ComputeTarget\r\n",
        "aml_compute_target = \"cpu-cluster\"\r\n",
        "try:\r\n",
        "    aml_compute = AmlCompute(workspace, aml_compute_target)\r\n",
        "    print(\"found existing compute target.\")\r\n",
        "except ComputeTargetException:\r\n",
        "    print(\"creating new compute target\")\r\n",
        "    \r\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\r\n",
        "                                                                min_nodes = 1, \r\n",
        "                                                                max_nodes = 4)    \r\n",
        "    aml_compute = ComputeTarget.create(workspace, aml_compute_target, provisioning_config)\r\n",
        "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\r\n",
        "    \r\n",
        "print(\"Azure Machine Learning Compute attached\")\r\n",
        "\r\n",
        "env = Environment.get(workspace=workspace, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\r\n",
        "# create a new runconfig object\r\n",
        "runconfig = RunConfiguration()\r\n",
        "runconfig.environment = env\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "found existing compute target.\nAzure Machine Learning Compute attached\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923073273
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_step = PythonScriptStep( name=\"prep_data\", \r\n",
        "                                script_name=\"data_engineering.py\", \r\n",
        "\t                            source_directory=\"data_engineering\", \r\n",
        "                                compute_target=aml_compute_target, \r\n",
        "                                runconfig=runconfig,\r\n",
        "                                allow_reuse=False                                \r\n",
        "\t                            )\r\n",
        "\r\n",
        "train_step    = PythonScriptStep( name=\"train\", \r\n",
        "                                script_name=\"train_2.py\", \r\n",
        "\t                            source_directory=\"train\", \r\n",
        "                                compute_target=aml_compute_target, \r\n",
        "                                runconfig=runconfig,\r\n",
        "                                allow_reuse=False\r\n",
        "\t                            )\r\n",
        "#train_step.run_after(dataprep_step)\r\n",
        "\r\n",
        "select_step   = PythonScriptStep( name=\"select_model\", \r\n",
        "                                script_name=\"model_select.py\", \r\n",
        "\t                            source_directory=\"model_selection\", \r\n",
        "                                compute_target=aml_compute_target, \r\n",
        "                                runconfig=runconfig,\r\n",
        "                                allow_reuse=False\r\n",
        "\t                            )\r\n",
        "#select_step.run_after(train_step)\r\n",
        "\r\n",
        "deploy_step   = PythonScriptStep( name=\"deploy_model\", \r\n",
        "                                script_name=\"deploy.py\", \r\n",
        "\t                            source_directory=\"model_deploy\", \r\n",
        "                                compute_target=aml_compute_target, \r\n",
        "                                runconfig=runconfig,\r\n",
        "                                allow_reuse=False\r\n",
        "\t                            )\r\n",
        "#deploy_step.run_after(select_step)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923073544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import StepSequence\r\n",
        "   \r\n",
        "experiment_name = 'MLOps-Workshop'\r\n",
        "\r\n",
        "step_sequence = StepSequence(steps=[dataprep_step, train_step, select_step, deploy_step])\r\n",
        "pipeline = Pipeline(workspace=workspace, steps=step_sequence)\r\n",
        "pipeline_run = Experiment(workspace, experiment_name).submit(pipeline)\r\n",
        "\r\n",
        "print(\"Pipeline is submitted for execution\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class KubernetesCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step prep_data [88fdee95][4c0b75f6-7a45-4b70-b9a7-b7c602120b97], (This step will run and generate new outputs)\nCreated step train [b09b8f1b][3d2f614f-08cb-4d84-90e4-7d4da556831f], (This step will run and generate new outputs)\nCreated step select_model [edfb6c9e][73f707ac-9a6e-4bb5-be0b-ea1aa6a1f607], (This step will run and generate new outputs)\nCreated step deploy_model [2583151a][91e3aa2d-3e59-412d-8653-e0f55cdc4558], (This step will run and generate new outputs)\nSubmitted PipelineRun 858cb501-32b2-4d8c-897f-7e87afa85028\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/858cb501-32b2-4d8c-897f-7e87afa85028?wsid=/subscriptions/2fadeb06-9775-43ec-a256-ae5922c67d60/resourcegroups/mlops/workspaces/datamlops&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\nPipeline is submitted for execution\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923077785
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\r\n",
        "\r\n",
        "# replace uri below with your service endpoint\r\n",
        "uri = 'http://a9f21b4b-7143-4c8f-8578-58fb141f3a85.westeurope.azurecontainer.io/score'\r\n",
        "\r\n",
        "headers = {\"Content-Type\": \"application/json\"}\r\n",
        "comments = \"\"\"\r\n",
        "\"I've been using Dreamweaver (and it's predecessor Macromedia's UltraDev) for many years.  \r\n",
        "For someone who is an experienced web designer, this course is a high-level review of the CS5 version of Dreamweaver,\r\n",
        " but it doesn't go into a great enough level of detail to find it very useful.\\n\\nOn the other hand, \r\n",
        " this is a great tool for someone who is a relative novice at web design.  \r\n",
        " It starts off with a basic overview of HTML and continues through the concepts necessary to build a modern web site.  \r\n",
        " Someone who goes through this course should exit with enough knowledge to create something that does what \r\n",
        " you want it do do...within reason.  Don't expect to go off and build an entire e-commerce system with only this class \r\n",
        " under your belt.\\n\\nIt's important to note that there's a long gap from site design to actual implementation.  \r\n",
        " This course teaches you how to implement a design.  The user interface and overall user experience is a different \r\n",
        " subject that isn't covered here...it's possible to do a great implementation of an absolutely abysmal design.  \r\n",
        " I speak from experience.  :)\\n\\nAs I said above, if you're a novice, a relative newcomer or just an experienced web \r\n",
        " designer who wants a refresher course, this is a good way to do it.\"\r\n",
        "\"\"\"\r\n",
        "sample_input = json.dumps({\r\n",
        "    'data': [comments]\r\n",
        "})\r\n",
        "response = requests.post(uri, data=sample_input, headers=headers)\r\n",
        "print(response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[4.0]\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923978520
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Publish Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline.publish(\r\n",
        "     name=\"MLOps-Workshop-Pipeline\",\r\n",
        "     description=\"Published Pipeline for MLOps Workshop\")\r\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923078413
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline.id"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'00288b87-9585-4a50-9c9b-a3eaae47f01a'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923078727
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schedule Pipeline runs\r\n",
        "\r\n",
        "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-trigger-published-pipeline\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\r\n",
        "\r\n",
        "## create time-based pipeline\r\n",
        "## Frequency can be Minute / Hour / Day / Week / Month\r\n",
        "#recurrence = ScheduleRecurrence(frequency=\"Month\", interval=1)\r\n",
        "#recurring_schedule = Schedule.create(workspace, name=\"MonthlySchedule\", \r\n",
        "#                            description=\"Based on time\",\r\n",
        "#                            pipeline_id=published_pipeline.id, \r\n",
        "#                            experiment_name=experiment_name, \r\n",
        "#                            recurrence=recurrence)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923078938
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recurring_schedule\r\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923079161
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline Schedule Management\r\n",
        "\r\n",
        "- Enable / Disable\r\n",
        "\r\n",
        "enable(wait_for_provisioning=False, wait_timeout=3600)\r\n",
        "\r\n",
        "disable(wait_for_provisioning=False, wait_timeout=3600)\r\n",
        "\r\n",
        "- Get (Set the schedule to 'Active' and available to run)\r\n",
        "\r\n",
        "get(workspace, id, _workflow_provider=None, _service_endpoint=None)\r\n",
        "\r\n",
        "- List ( Get all schedules in the current workspace)\r\n",
        "\r\n",
        "list(workspace, active_only=True, pipeline_id=None, pipeline_endpoint_id=None, _workflow_provider=None, _service_endpoint=None)\r\n",
        "\r\n",
        "https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-setup-schedule-for-a-published-pipeline.ipynb\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#recurring_schedule.disable(wait_for_provisioning=True)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1646923079366
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}